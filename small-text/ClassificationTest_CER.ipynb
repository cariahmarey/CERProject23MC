{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a4b427a-1e9d-40ae-98ae-0c05fa21a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the rcParams module from the matplotlib library to customize plot appearance\n",
    "from matplotlib import rcParams\n",
    "# Update the font size of the x-axis and y-axis labels, as well as the overall axis labels\n",
    "rcParams.update({'xtick.labelsize': 14, 'ytick.labelsize': 14, 'axes.labelsize': 16})\n",
    "\n",
    "# Import the torch and numpy libraries for numerical computations\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set a seed value for reproducibility in random number generation\n",
    "seed = 2022\n",
    "torch.manual_seed(seed)  # Set the seed for PyTorch\n",
    "np.random.seed(seed)     # Set the seed for NumPy\n",
    "\n",
    "# Import the logging, glob, os, and pandas libraries for file handling and data manipulation\n",
    "import logging\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Read the initial training data from a CSV file into a pandas DataFrame\n",
    "#initial_data = pd.read_csv(\"initial_train_updated.CSV\", delimiter='\\t', index_col=False)\n",
    "initial_data = pd.read_csv(\"initial_train_smalltext.csv\", delimiter='\\t', index_col=False)\n",
    "\n",
    "# Get the number of unique classes in the 'Label.Marius' column of the initial training data\n",
    "num_classes = initial_data['label'].nunique()\n",
    "\n",
    "# Define the path to the 'Training Data' directory\n",
    "path = r'./Training Data'\n",
    "\n",
    "# Use the glob library to get a list of all CSV files in the specified directory and its subdirectories\n",
    "all_files = glob.glob(os.path.join(path, \"**/*.csv\"), recursive=True)\n",
    "\n",
    "# Read and concatenate all the CSV files into a single pandas DataFrame\n",
    "new_data = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c821db9-81bf-437c-8c39-2addf2ea7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy library for numerical computations\n",
    "import numpy as np\n",
    "# Import the LABEL_IGNORED and LABEL_UNLABELED constants from the small_text.base module\n",
    "from small_text.base import LABEL_IGNORED, LABEL_UNLABELED\n",
    "\n",
    "# Convert the 'label' column of the initial_data DataFrame into a categorical variable\n",
    "initial_data['label'] = pd.Categorical(initial_data.label)\n",
    "# Create a new column 'code' in the initial_data DataFrame that contains the numerical codes of the categorical labels\n",
    "initial_data['code'] = initial_data['label'].cat.codes\n",
    "\n",
    "# Create a new DataFrame 'df' by converting lists of tuples into a pandas DataFrame\n",
    "# The DataFrame has three columns: 'example', 'label', and 'code'\n",
    "# The 'example' column contains the values from the 'profile' column of the new_data DataFrame\n",
    "# The 'label' column contains the string 'LABEL_UNLABELED' for all rows\n",
    "# The 'code' column contains the numerical value of the LABEL_UNLABELED constant for all rows\n",
    "df = pd.DataFrame(\n",
    "    list(zip(new_data.example,  # use column \"text\"\n",
    "             ['LABEL_UNLABELED'] * new_data.shape[0],\n",
    "             [LABEL_UNLABELED] * new_data.shape[0])),\n",
    "    columns=['example', 'label', 'code'])\n",
    "\n",
    "# Concatenate the initial_data and df DataFrames along the row axis\n",
    "# The resulting DataFrame 'input_data' has a multi-level index with two levels: 'Initial Training' and 'Twitter Data'\n",
    "input_data = pd.concat([initial_data, df], keys=['Initial Training', 'Twitter Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9644f8ba-ae95-4689-96b3-67e81cca20c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/mi859qefe/.local/lib/python3.11/site-packages/small_text/utils/annotations.py:67: ExperimentalWarning: The function from_arrays is experimental and maybe subject to change soon.\n",
      "  warnings.warn(f'The {subject} {func_or_class.__name__} is experimental '\n"
     ]
    }
   ],
   "source": [
    "# Import the TextDataset class from the small_text module.\n",
    "from small_text import TextDataset\n",
    "\n",
    "# Creates an array of numbers from 0 to num_classes-1. The variable num_classes is presumably defined elsewhere in the code.\n",
    "target_labels = np.arange(num_classes)\n",
    "\n",
    "# Prints the array of target labels to the console.\n",
    "print(target_labels)\n",
    "\n",
    "# Creating an instance of the TextDataset using the `from_arrays` class method. This requires several arguments:\n",
    "# 1. A list of examples obtained from the 'example' column of the input_data dataframe.\n",
    "# 2. An array of codes obtained from the 'code' column of the input_data dataframe.\n",
    "# 3. The target labels, which is an array of integers from 0 to num_classes-1.\n",
    "train = TextDataset.from_arrays(\n",
    "    input_data.example.tolist(),\n",
    "    input_data.code.to_numpy(),\n",
    "    target_labels=target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fcfb2b6-782c-4574-b5b9-34a4f790da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pickle\n",
    "\n",
    "num_queries = 1\n",
    "\n",
    "#def evaluate(active_learner, train, test):\n",
    "#y_pred = active_learner.classifier.predict(train)\n",
    "#y_pred_test = active_learner.classifier.predict(test)\n",
    "#test_acc = accuracy_score(y_pred_test, test.y)\n",
    "#print('Train accuracy: {:.2f}'.format(accuracy_score(y_pred, train.y)))\n",
    "#print('Test accuracy: {:.2f}'.format(test_acc))\n",
    "#return test_acc\n",
    "\n",
    "# Load the pickled model\n",
    "with open('active_learner_cer.pkl', 'rb') as file:\n",
    "    active_learner = pickle.load(file)\n",
    "\n",
    "# evaluate the performance of the active learner on the training data,\n",
    "# by computing the F1 score\n",
    "def evaluate(active_learner, train_set): \n",
    "\n",
    "    # active_learner: instance of PoolBasedActiveLearner class, which is a\n",
    "    # pool-based active learning framework\n",
    "    y_pred = active_learner.classifier.predict(train_set)\n",
    "    #y_pred_test = active_learner.classifier.predict(test)\n",
    "    \n",
    "    print(y_pred)\n",
    "    print(train_set.y) #print true true labels of training data\n",
    "\n",
    "    # f1: evaluation metric for multi-class classification\n",
    "    print('Train f1: {:.2f}'.format(\n",
    "        f1_score(y_pred, train_set.y, average='macro')))\n",
    "    print('---')\n",
    "\n",
    "results = []\n",
    "#results.append(evaluate(active_learner, train[indices_labeled], test)) results.append(evaluate(active_learner, train[indices_labeled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "013a237c-9bf4-4084-ba0e-8f6dede215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from small_text import TextDataset\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e49e8bed-c84f-4152-a53e-44a3979bb180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Model\n",
    "with open('active_learner_cer.pkl', 'rb') as file:\n",
    "    active_learner = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17bc0b50-f7e5-4d4a-8979-e24493bbc15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/mi859qefe/.local/lib/python3.11/site-packages/small_text/utils/annotations.py:67: ExperimentalWarning: The function from_arrays is experimental and maybe subject to change soon.\n",
      "  warnings.warn(f'The {subject} {func_or_class.__name__} is experimental '\n"
     ]
    }
   ],
   "source": [
    "# 2. Load the Test Data\n",
    "#test_data = pd.read_csv(\"labeled_testdata_smalltext.csv\")\n",
    "test_data = pd.read_csv(\"labeled_testdata_smalltext.csv\", delimiter='\\t', index_col=False)\n",
    "test_examples = test_data[\"example\"].tolist()\n",
    "true_labels = test_data[\"label\"].tolist()\n",
    "\n",
    "# Convert test examples and labels into a dataset object\n",
    "test_dataset = TextDataset.from_arrays(test_examples, np.zeros_like(true_labels), target_labels=target_labels)\n",
    "\n",
    "# Predict with the Model\n",
    "predicted_probas = active_learner.classifier.predict_proba(test_dataset)\n",
    "predicted_labels = np.argmax(predicted_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2296f367-7b9a-4a5e-aad0-3e6478af0a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Predict with the Model\n",
    "predicted_probas = active_learner.classifier.predict_proba(test_dataset)\n",
    "predicted_labels = np.argmax(predicted_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "689c6463-49d7-43ae-8bfa-72cc1f7b1a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate the Model\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "233541c9-c80f-429c-933f-5b32476f28bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.96      0.93      0.95        28\n",
      "           2       0.92      1.00      0.96        23\n",
      "           3       1.00      1.00      1.00        27\n",
      "           4       1.00      0.91      0.95        11\n",
      "           5       1.00      1.00      1.00        24\n",
      "           6       0.96      0.97      0.97        77\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.98      0.96      0.97       200\n",
      "weighted avg       0.97      0.97      0.97       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee699dd-1f67-4f1e-82da-c1cd352277ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
