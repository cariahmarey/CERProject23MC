{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "foreign-enough",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install small-text[transformers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attended-abuse",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install setfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17587b6-2513-4a3c-980a-b7269bee14fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5ae34a2-4677-4cc7-8396-b84aa3396236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "healthy-jones",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hazardous-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              example  \\\n",
      "0   hier twittert das Team von Petra Pau/Marzahn-H...   \n",
      "1   Die soziale Opposition: Feministisch. Sozialis...   \n",
      "2   MdB DIE LINKE l Stellvertretende Fraktionsvors...   \n",
      "3   MdB f√ºr die Menschen in der St√§dteregion Aache...   \n",
      "4   Mitglied des Bundestages | Sprecherin f√ºr Arbe...   \n",
      "..                                                ...   \n",
      "65  Mitglied des Deutschen Bundestages | Ausw√§rtig...   \n",
      "66  Ostwestfale seit Geburt! Zur Zeit aktiv in MV,...   \n",
      "67              Nein.  Nicht F. Jacobi,  ein anderer!   \n",
      "68  Dipl.-Ing.(BA) Mechatronik | industrial automa...   \n",
      "69    üåà F√ºr die Menschen und Twitter-Bots \"ganz Ohr\".   \n",
      "\n",
      "                            label  \n",
      "0   0 √∂konomisch links + libert√§r  \n",
      "1   0 √∂konomisch links + libert√§r  \n",
      "2   0 √∂konomisch links + libert√§r  \n",
      "3   0 √∂konomisch links + libert√§r  \n",
      "4   0 √∂konomisch links + libert√§r  \n",
      "..                            ...  \n",
      "65              6 keine Kategorie  \n",
      "66              6 keine Kategorie  \n",
      "67              6 keine Kategorie  \n",
      "68              6 keine Kategorie  \n",
      "69              6 keine Kategorie  \n",
      "\n",
      "[70 rows x 2 columns]\n",
      "----------------------------\n",
      "                                                example\n",
      "0     Bundestagsabgeordnete. Sozialdemokratin. Biele...\n",
      "1     Bundestagsabgeordnete @spdbt f√ºr #Schaumburg &...\n",
      "2     Im Deutschen Bundestag f√ºr Pforzheim/Enzkreis,...\n",
      "3     Direkt gew√§hlter Abgeordneter des Wahlkreises ...\n",
      "4     MdB 2013-2021 ‚Ä¢ SPD ‚Ä¢ Diplom-Biologe ‚Ä¢ aktiver...\n",
      "...                                                 ...\n",
      "1973  Staatssekret√§r @UmweltHessen, Natursch√ºtzer au...\n",
      "1974  Digitalstaatssekret√§r und CIO des Landes Hesse...\n",
      "1975  Guido Wolf, CDU, Justizminister Baden-W√ºrttemb...\n",
      "1976  –ù–æ–≤–æ–ø—Ä–∏–∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–æ–ª –ù—ñ–º–µ—á—á–∏–Ω–∏ –≤ –£–∫—Ä–∞—ó–Ω—ñ. // ...\n",
      "1977  Aufsichtsr√§tin, Staatssekret√§rin a.D,  2006-20...\n",
      "\n",
      "[1978 rows x 1 columns]\n",
      "----------------------------\n",
      "First 2 training samples:\n",
      "\n",
      "hier twittert das Team von Petra Pau/Marzahn-Hellersdorf #mahe  PAUer f√ºr die LINKE   0 √∂konomisch links + libert√§r\n",
      "Die soziale Opposition: Feministisch. Sozialistisch. Friedlich. F√ºr dich! üïäü¶∫üå≥‚úä   0 √∂konomisch links + libert√§r\n",
      "First 2 future samples:\n",
      "\n",
      "Bundestagsabgeordnete. Sozialdemokratin. Bielefelderin.   0 √∂konomisch links + libert√§r\n",
      "Bundestagsabgeordnete @spdbt f√ºr #Schaumburg & #Nienburg, #Niedersachsen | #Verteidigung, #Bundeswehr, #Bildung, #Digitalisierung | Kaffee, Lehrerin, @seeheimer   0 √∂konomisch links + libert√§r\n",
      "----------------------------\n",
      "0       Bundestagsabgeordnete. Sozialdemokratin. Biele...\n",
      "1       Bundestagsabgeordnete @spdbt f√ºr #Schaumburg &...\n",
      "2       Im Deutschen Bundestag f√ºr Pforzheim/Enzkreis,...\n",
      "3       Direkt gew√§hlter Abgeordneter des Wahlkreises ...\n",
      "4       MdB 2013-2021 ‚Ä¢ SPD ‚Ä¢ Diplom-Biologe ‚Ä¢ aktiver...\n",
      "                              ...                        \n",
      "1973    Staatssekret√§r @UmweltHessen, Natursch√ºtzer au...\n",
      "1974    Digitalstaatssekret√§r und CIO des Landes Hesse...\n",
      "1975    Guido Wolf, CDU, Justizminister Baden-W√ºrttemb...\n",
      "1976    –ù–æ–≤–æ–ø—Ä–∏–∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–æ–ª –ù—ñ–º–µ—á—á–∏–Ω–∏ –≤ –£–∫—Ä–∞—ó–Ω—ñ. // ...\n",
      "1977    Aufsichtsr√§tin, Staatssekret√§rin a.D,  2006-20...\n",
      "Name: example, Length: 1978, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Import the rcParams module from the matplotlib library to customize plot appearance\n",
    "from matplotlib import rcParams\n",
    "# Update the font size of the x-axis and y-axis labels, as well as the overall axis labels\n",
    "rcParams.update({'xtick.labelsize': 14, 'ytick.labelsize': 14, 'axes.labelsize': 16})\n",
    "\n",
    "# Import the torch and numpy libraries for numerical computations\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set a seed value for reproducibility in random number generation\n",
    "seed = 2022\n",
    "torch.manual_seed(seed)  # Set the seed for PyTorch\n",
    "np.random.seed(seed)     # Set the seed for NumPy\n",
    "\n",
    "# Import the logging, glob, os, and pandas libraries for file handling and data manipulation\n",
    "import logging\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Read the initial training data from a CSV file into a pandas DataFrame\n",
    "#initial_data = pd.read_csv(\"initial_train_updated.CSV\", delimiter='\\t', index_col=False)\n",
    "initial_data = pd.read_csv(\"initial_train_smalltext.csv\", delimiter='\\t', index_col=False)\n",
    "print(initial_data)  # Print the initial training data\n",
    "\n",
    "# Get the number of unique classes in the 'Label.Marius' column of the initial training data\n",
    "num_classes = initial_data['label'].nunique()\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "# Define the path to the 'Training Data' directory\n",
    "path = r'./Training Data'\n",
    "\n",
    "# Use the glob library to get a list of all CSV files in the specified directory and its subdirectories\n",
    "all_files = glob.glob(os.path.join(path, \"**/*.csv\"), recursive=True)\n",
    "\n",
    "# Read and concatenate all the CSV files into a single pandas DataFrame\n",
    "new_data = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "print(new_data)  # Print the concatenated data\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "# Print the first 2 training samples from the initial training data\n",
    "print('First 2 training samples:\\n')\n",
    "for i in range(2):\n",
    "    print(initial_data.iloc[i, 0], ' ', initial_data.iloc[i, 1])\n",
    "\n",
    "# Print the first 2 future samples from the concatenated data\n",
    "print('First 2 future samples:\\n')\n",
    "for i in range(2):\n",
    "    print(new_data.iloc[i, 0], ' ', initial_data.iloc[i, 1])\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "# Print the profile attribute of the new_data DataFrame \n",
    "print(new_data.example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00cbe7f-a743-47b6-b8d1-eb1158397953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              example  \\\n",
      "0   hier twittert das Team von Petra Pau/Marzahn-H...   \n",
      "1   Die soziale Opposition: Feministisch. Sozialis...   \n",
      "2   MdB DIE LINKE l Stellvertretende Fraktionsvors...   \n",
      "3   MdB f√ºr die Menschen in der St√§dteregion Aache...   \n",
      "4   Mitglied des Bundestages | Sprecherin f√ºr Arbe...   \n",
      "..                                                ...   \n",
      "65  Mitglied des Deutschen Bundestages | Ausw√§rtig...   \n",
      "66  Ostwestfale seit Geburt! Zur Zeit aktiv in MV,...   \n",
      "67              Nein.  Nicht F. Jacobi,  ein anderer!   \n",
      "68  Dipl.-Ing.(BA) Mechatronik | industrial automa...   \n",
      "69    üåà F√ºr die Menschen und Twitter-Bots \"ganz Ohr\".   \n",
      "\n",
      "                            label  code  \n",
      "0   0 √∂konomisch links + libert√§r     0  \n",
      "1   0 √∂konomisch links + libert√§r     0  \n",
      "2   0 √∂konomisch links + libert√§r     0  \n",
      "3   0 √∂konomisch links + libert√§r     0  \n",
      "4   0 √∂konomisch links + libert√§r     0  \n",
      "..                            ...   ...  \n",
      "65              6 keine Kategorie     6  \n",
      "66              6 keine Kategorie     6  \n",
      "67              6 keine Kategorie     6  \n",
      "68              6 keine Kategorie     6  \n",
      "69              6 keine Kategorie     6  \n",
      "\n",
      "[70 rows x 3 columns]\n",
      "--------\n",
      "                                                example            label  code\n",
      "0     Bundestagsabgeordnete. Sozialdemokratin. Biele...  LABEL_UNLABELED    -1\n",
      "1     Bundestagsabgeordnete @spdbt f√ºr #Schaumburg &...  LABEL_UNLABELED    -1\n",
      "2     Im Deutschen Bundestag f√ºr Pforzheim/Enzkreis,...  LABEL_UNLABELED    -1\n",
      "3     Direkt gew√§hlter Abgeordneter des Wahlkreises ...  LABEL_UNLABELED    -1\n",
      "4     MdB 2013-2021 ‚Ä¢ SPD ‚Ä¢ Diplom-Biologe ‚Ä¢ aktiver...  LABEL_UNLABELED    -1\n",
      "...                                                 ...              ...   ...\n",
      "1973  Staatssekret√§r @UmweltHessen, Natursch√ºtzer au...  LABEL_UNLABELED    -1\n",
      "1974  Digitalstaatssekret√§r und CIO des Landes Hesse...  LABEL_UNLABELED    -1\n",
      "1975  Guido Wolf, CDU, Justizminister Baden-W√ºrttemb...  LABEL_UNLABELED    -1\n",
      "1976  –ù–æ–≤–æ–ø—Ä–∏–∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–æ–ª –ù—ñ–º–µ—á—á–∏–Ω–∏ –≤ –£–∫—Ä–∞—ó–Ω—ñ. // ...  LABEL_UNLABELED    -1\n",
      "1977  Aufsichtsr√§tin, Staatssekret√§rin a.D,  2006-20...  LABEL_UNLABELED    -1\n",
      "\n",
      "[1978 rows x 3 columns]\n",
      "--------\n",
      "                                                                 example  \\\n",
      "Initial Training 0     hier twittert das Team von Petra Pau/Marzahn-H...   \n",
      "                 1     Die soziale Opposition: Feministisch. Sozialis...   \n",
      "                 2     MdB DIE LINKE l Stellvertretende Fraktionsvors...   \n",
      "                 3     MdB f√ºr die Menschen in der St√§dteregion Aache...   \n",
      "                 4     Mitglied des Bundestages | Sprecherin f√ºr Arbe...   \n",
      "...                                                                  ...   \n",
      "Twitter Data     1973  Staatssekret√§r @UmweltHessen, Natursch√ºtzer au...   \n",
      "                 1974  Digitalstaatssekret√§r und CIO des Landes Hesse...   \n",
      "                 1975  Guido Wolf, CDU, Justizminister Baden-W√ºrttemb...   \n",
      "                 1976  –ù–æ–≤–æ–ø—Ä–∏–∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–æ–ª –ù—ñ–º–µ—á—á–∏–Ω–∏ –≤ –£–∫—Ä–∞—ó–Ω—ñ. // ...   \n",
      "                 1977  Aufsichtsr√§tin, Staatssekret√§rin a.D,  2006-20...   \n",
      "\n",
      "                                               label  code  \n",
      "Initial Training 0     0 √∂konomisch links + libert√§r     0  \n",
      "                 1     0 √∂konomisch links + libert√§r     0  \n",
      "                 2     0 √∂konomisch links + libert√§r     0  \n",
      "                 3     0 √∂konomisch links + libert√§r     0  \n",
      "                 4     0 √∂konomisch links + libert√§r     0  \n",
      "...                                              ...   ...  \n",
      "Twitter Data     1973                LABEL_UNLABELED    -1  \n",
      "                 1974                LABEL_UNLABELED    -1  \n",
      "                 1975                LABEL_UNLABELED    -1  \n",
      "                 1976                LABEL_UNLABELED    -1  \n",
      "                 1977                LABEL_UNLABELED    -1  \n",
      "\n",
      "[2048 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the numpy library for numerical computations\n",
    "import numpy as np\n",
    "# Import the LABEL_IGNORED and LABEL_UNLABELED constants from the small_text.base module\n",
    "from small_text.base import LABEL_IGNORED, LABEL_UNLABELED\n",
    "\n",
    "# Convert the 'label' column of the initial_data DataFrame into a categorical variable\n",
    "initial_data['label'] = pd.Categorical(initial_data.label)\n",
    "# Create a new column 'code' in the initial_data DataFrame that contains the numerical codes of the categorical labels\n",
    "initial_data['code'] = initial_data['label'].cat.codes\n",
    "\n",
    "# Print the initial_data DataFrame with the new 'code' column\n",
    "print(initial_data)\n",
    "print(\"--------\")\n",
    "\n",
    "# Create a new DataFrame 'df' by converting lists of tuples into a pandas DataFrame\n",
    "# The DataFrame has three columns: 'example', 'label', and 'code'\n",
    "# The 'example' column contains the values from the 'profile' column of the new_data DataFrame\n",
    "# The 'label' column contains the string 'LABEL_UNLABELED' for all rows\n",
    "# The 'code' column contains the numerical value of the LABEL_UNLABELED constant for all rows\n",
    "df = pd.DataFrame(\n",
    "    list(zip(new_data.example,  # use column \"text\"\n",
    "             ['LABEL_UNLABELED'] * new_data.shape[0],\n",
    "             [LABEL_UNLABELED] * new_data.shape[0])),\n",
    "    columns=['example', 'label', 'code'])\n",
    "\n",
    "# Print the newly created DataFrame 'df'\n",
    "print(df)\n",
    "print(\"--------\")\n",
    "\n",
    "# Concatenate the initial_data and df DataFrames along the row axis\n",
    "# The resulting DataFrame 'input_data' has a multi-level index with two levels: 'Initial Training' and 'Twitter Data'\n",
    "input_data = pd.concat([initial_data, df], keys=['Initial Training', 'Twitter Data'])\n",
    "\n",
    "# Print the concatenated DataFrame 'input_data'\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "199260fa-a5c3-404b-b93a-82057c9253b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pickle\n",
    "\n",
    "num_queries = 1\n",
    "\n",
    "#def evaluate(active_learner, train, test):\n",
    "#y_pred = active_learner.classifier.predict(train)\n",
    "#y_pred_test = active_learner.classifier.predict(test)\n",
    "#test_acc = accuracy_score(y_pred_test, test.y)\n",
    "#print('Train accuracy: {:.2f}'.format(accuracy_score(y_pred, train.y)))\n",
    "#print('Test accuracy: {:.2f}'.format(test_acc))\n",
    "#return test_acc\n",
    "\n",
    "# Load the pickled model\n",
    "with open('active_learner_cer.pkl', 'rb') as file:\n",
    "    active_learner = pickle.load(file)\n",
    "\n",
    "# evaluate the performance of the active learner on the training data,\n",
    "# by computing the F1 score\n",
    "def evaluate(active_learner, train_set): \n",
    "\n",
    "    # active_learner: instance of PoolBasedActiveLearner class, which is a\n",
    "    # pool-based active learning framework\n",
    "    y_pred = active_learner.classifier.predict(train_set)\n",
    "    #y_pred_test = active_learner.classifier.predict(test)\n",
    "    \n",
    "    print(y_pred)\n",
    "    print(train_set.y) #print true true labels of training data\n",
    "\n",
    "    # f1: evaluation metric for multi-class classification\n",
    "    print('Train f1: {:.2f}'.format(\n",
    "        f1_score(y_pred, train_set.y, average='macro')))\n",
    "    print('---')\n",
    "\n",
    "results = []\n",
    "#results.append(evaluate(active_learner, train[indices_labeled], test)) results.append(evaluate(active_learner, train[indices_labeled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e604d517-5bff-4016-a774-1182fcbcc4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e98cafc959f4e039544389911f635d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 16800\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 525\n",
      "  Total train batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa844dcca6404ab2a4d5962ccad14991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31e73532bc2452aaf4ad86e97f2912b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/525 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 2 6 3 3 5 3 5 2 0 1 2 6 3 5 5 5 6 3 2 6 6 5 0 5 5 3 5 5 3 6 1 5 2 6 5\n",
      " 5 6 5 5 5 6 5 3 6 5 5 5 0 6 5 4 3 6 1 4 5 2 6 5 3 6 1 5 5 6 3 5 3]\n",
      "---------------\n",
      "Iteration #1 (420 samples)\n",
      "[3 6 2 6 3 3 5 3 5 2 0 1 2 6 3 5 5 5 6 3 2 6 6 5 0 5 5 3 5 5 3 6 1 5 2 6 5\n",
      " 5 6 5 5 5 6 5 3 6 5 5 5 0 6 5 4 3 6 1 4 5 2 6 5 3 6 1 5 5 6 3 5 3 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 5 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4\n",
      " 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 3 1 1 6 6 6\n",
      " 1 1 0 6 6 1 0 6 3 1 6 3 6 3 3 1 1 6 2 6 2 1 1 5 5 1 0 1 0 6 6 6 6 6 3 1 0\n",
      " 3 2 6 6 6 5 6 4 1 3 4 6 6 6 2 2 6 1 6 2 3 3 6 6 2 3 0 4 2 2 6 4 2 2 6 6 3\n",
      " 2 2 2 3 0 0 2 2 6 0 1 5 4 0 0 2 0 0 0 2 3 4 6 3 0 3 2 4 3 6 2 2 3 4 2 0 6\n",
      " 2 0 3 2 0 2 4 6 6 4 1 2 3 6 0 2 2 2 0 3 4 1 6 6 2 1 0 3 1 2 5 1 1 5 1 1 2\n",
      " 6 3 2 1 6 2 3 5 2 6 1 1 5 2 6 1 6 6 0 6 4 5 5 6 6 1 6 2 3 1 1 5 2 2 0 6 5\n",
      " 2 6 0 1 5 6 6 4 6 6 2 3 6 2 6 5 1 6 6 5 6 6 6 6 3 1 6 2 6 2 4 4 0 6 2 2 6\n",
      " 1 3 1 6 6 4 2 1 0 3 6 0 4 2 3 6 1 3 3 1 3 3 5 3 5 3 3 5 3 3 1 3 3 6 2 6 3\n",
      " 3 3 3 5 6 3 6 3 3 3 1 6 5]\n",
      "[3 6 2 6 3 3 5 3 5 2 0 1 2 6 3 5 5 5 6 3 2 6 6 5 0 5 5 3 5 5 3 6 1 5 2 6 5\n",
      " 5 6 5 5 5 6 5 3 6 5 5 5 0 6 5 4 3 6 1 4 5 2 6 5 3 6 1 5 5 6 3 5 3 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4\n",
      " 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 3 1 1 6 6 6\n",
      " 1 1 0 6 6 1 0 6 3 1 6 3 6 3 3 1 1 6 2 6 2 1 1 5 5 1 0 1 0 6 6 6 6 6 3 1 0\n",
      " 3 2 6 6 6 5 6 4 1 3 4 6 6 6 2 2 6 1 6 2 3 3 6 6 2 3 0 4 2 2 6 4 2 2 6 6 3\n",
      " 2 2 2 3 0 0 2 2 6 0 1 5 4 0 0 2 0 0 0 2 3 4 6 3 0 3 2 4 3 6 2 2 4 4 2 0 6\n",
      " 2 0 3 2 0 2 4 6 6 4 1 2 3 6 0 2 2 2 0 3 4 1 6 6 2 1 0 3 1 2 5 1 1 5 1 1 2\n",
      " 6 3 2 1 6 2 3 5 2 6 1 1 5 2 6 1 0 6 0 6 4 5 5 6 6 1 6 2 3 1 1 5 2 2 0 6 5\n",
      " 2 6 0 1 5 6 6 4 6 6 2 3 6 2 6 5 1 6 6 5 6 6 6 6 3 1 6 2 6 2 4 4 0 6 2 2 6\n",
      " 1 3 1 6 6 4 2 1 0 3 6 0 4 2 3 6 1 3 3 1 3 3 5 3 5 3 3 5 3 3 1 3 3 6 2 6 3\n",
      " 3 3 3 5 6 3 6 3 3 3 1 6 5]\n",
      "Train f1: 0.99\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# 3: import of xlsx with true labels (repeat)\n",
    "import numpy as np\n",
    "import pickle \n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickled model\n",
    "with open('active_learner_cer.pkl', 'rb') as file:\n",
    "    active_learner = pickle.load(file)\n",
    "    \n",
    "train = active_learner.dataset\n",
    "\n",
    "indices_labeled = active_learner.indices_labeled\n",
    "\n",
    "results = []\n",
    "    \n",
    "indices_queried = active_learner.query(num_samples=70)\n",
    "probas = active_learner.classifier.predict_proba(train[indices_queried])\n",
    "y_predicted = np.argmax(probas, axis=1)\n",
    "\n",
    "y = []\n",
    "\n",
    "# Read the xlsx file with sheetname and column name\n",
    "df = pd.read_excel('CER_ClassificationProcess.xlsx', sheet_name='predicted_labels_cer_5', usecols=['true label'])\n",
    "y = df['true label'].tolist()\n",
    "\n",
    "y = np.asarray(y).astype(\"int16\")\n",
    "\n",
    "# Return the labels for the current query to the active learner.\n",
    "active_learner.update(y)\n",
    "\n",
    "train_set_y = train.y\n",
    "train_set_y[indices_queried] = y\n",
    "train.y = train_set_y\n",
    "\n",
    "indices_labeled = np.concatenate([indices_queried, indices_labeled])\n",
    "\n",
    "print(y)\n",
    "\n",
    "print('---------------')\n",
    "print(f'Iteration #{i} ({len(indices_labeled)} samples)')\n",
    "#results.append(evaluate(active_learner, train[indices_labeled], test))\n",
    "results.append(evaluate(active_learner, train[indices_labeled]))\n",
    "\n",
    "# pickle the model\n",
    "with open('active_learner_cer.pkl', 'wb') as file:\n",
    "    pickle.dump(active_learner, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5210e7f9-34ac-493c-9a7d-b0c0bb350062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 6 6 3 3 5 3 5 2 6 6 6 6 3 5 5 5 6 3 2 6 6 5 0 5 5 3 5 5 3 6 1 5 2 6 5\n",
      " 5 6 5 6 5 6 5 3 6 5 5 5 0 2 5 4 3 3 1 4 5 6 6 5 3 6 1 5 5 6 3 5 3]\n",
      "[]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter to continue... \n"
     ]
    }
   ],
   "source": [
    "# 4: second & following predictions\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "# Load the pickled model\n",
    "with open('active_learner_cer.pkl', 'rb') as file:\n",
    "    active_learner = pickle.load(file)\n",
    "\n",
    "#active_learner._clf_factory.kwargs['max_iter'] = 2000\n",
    "active_learner._clf.model.max_iter = 2000\n",
    "active_learner._clf.model.class_weight = 'balanced'\n",
    "    \n",
    "train = active_learner.dataset\n",
    "\n",
    "indices_labeled = active_learner.indices_labeled\n",
    "\n",
    "results = []\n",
    "\n",
    "indices_queried = active_learner.query(num_samples=70)\n",
    "probas = active_learner.classifier.predict_proba(train[indices_queried])\n",
    "y_predicted = np.argmax(probas, axis=1)\n",
    "\n",
    "y = []\n",
    "\n",
    "print(y_predicted)\n",
    "\n",
    "# Write predicted labels to a CSV file\n",
    "with open('Predicted Labels/predicted_labels_cer_5.csv', mode='w', newline='') as file:\n",
    "    fieldnames = ['text', 'prediction', 'true label']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for j in range(len(indices_queried)):\n",
    "        writer.writerow({'text': train.x[indices_queried[j]], 'prediction': y_predicted[j], 'true label': \"\"})\n",
    "\n",
    "print(y)        \n",
    "\n",
    "# Ask the user to continue\n",
    "input(\"Press Enter to continue...\") \n",
    "#Simulate user interaction here. Replace this for real-world usage.\n",
    "#y = train.y[indices_queried]\n",
    "\n",
    "# pickle the model\n",
    "with open('active_learner_cer.pkl', 'wb') as file:\n",
    "    pickle.dump(active_learner, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b8dddee-e4e8-4ad1-923c-853977fe53d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 102,   62,   24,   12,   78,  127,   73,  106,  221,  144,   29,\n",
       "         29,   17,   25,   26, 1325])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sampling import _get_class_histogram\n",
    "\n",
    "# get histogram of predictions\n",
    "_get_class_histogram(active_learner.y, num_classes = 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
